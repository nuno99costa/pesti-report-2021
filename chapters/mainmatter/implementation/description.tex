%!TEX root=../../../main.tex

\subsection{Description}

In this section, we describe the implementation of the proposed solution. The first subsection explains the initial configuration of the development and production environment. The following section exposes the code implementation.

\subsubsection{Environment Configuration}

The project was developed in Python, and as such a Python environment was required to develop and deploy. It was also necessary to prepare the \acrshort{cam2} software package to connect to the developed software.

\paragraph{Python Environment}

Initially a Docker container was used, as there was issues with Windows and certain Python libraries used by Ray Tune. This Docker container, based on a \acrfull{alp}, contained the necessary software packages, runtime environments as well as the Python packages required to run Ray Tune.

Further into the development process it became possible to use Ray Tune in the developers laptop and as such we moved development away from Docker and into a \acrfull{anaconda}. This allowed us to remove unnecessary complexity from the developed system. Although \acrshort{anaconda} does provide virtual environment capabilities, these were not used in this project as there was only one ``container'' in usage and therefore only one virtual environment. This environment can be activated and accessed as seen in the code excerpt \ref{lst:anaconda}.

\begin{lstlisting}[language=Python, caption=Managing a Conda environment, captionpos=b, label={lst:anaconda}]
#Create a Conda environment
conda create --name {environment_name}

#Activate a Conda environment
conda activate {environment_name}

#Install package in a Conda environment
conda install {package_name}
\end{lstlisting}

The developed tool requires a variety of Python packages. The most important ones are the Ray framework and its dependencies, the dependencies required for each of the usable optimization algorithms (which are not included in the default Ray installation) and the HTTP Requests library, required for the connection between the Python tool and the \acrshort{cam2} application. In order to manage these dependencies, we have used a requirements text file, containing the required packages. This allows for any developer, even if not using \acrshort{anaconda}, can quickly install the required dependencies. This requirement text file is part of the available features of the \acrfull{pip}.

\begin{lstlisting}[language=Python, caption=Requirement text file example, captionpos=b, label={lst:req}]
ray~=1.2.0
requests~=2.25.1
urllib3
\end{lstlisting}


\paragraph{\acrshort{cam2} Configuration}

To enable the web server within \acrshort{cam2}, we first needed to download the development version of the software and start it using the command in the code excerpt \ref{lst:cam2}.

\begin{lstlisting}[language=Python, caption=Starting \acrshort{cam2} with web server enabled, captionpos=b, label={lst:cam2}]
C:\ProgramData\FARO Technologies\InTouch\Applications\CAM2\11.46.93\FARO.CAM2.exe -Automate
\end{lstlisting}

\subsubsection{Code Implementation}

We split the code implementation into 3 different and important parts: the search space (used to define the optimizable functions parameters), the CAM2 interface, used to connect to the \acrshort{cam2} software) and the individual tuning setup (which defines the setup for executing an optimization run using a specified optimizable algorithm).

\paragraph{Search Spaces}

To create a search space, Ray Tune specifies a native interface. You can specify this search space when setting up a tuning session, using the \verb!config! parameter in the \verb!tune.run! method. This parameter consists of a dictionary, a Python data structure where data is stored in key:value pairs - in this framework, the keys are the hyper parameter names and the values are the possible values for the hyper parameter. An example of this parameter usage can be found in the code excerpt \ref{lst:searchspace}. Ray Tune allows to define hyper parameter search spaces as a single value, a list of values and as a random extraction from a value space or function. Throughout this internship, we have only used the \verb!quniform! search space function, which defines a search space quantized between two numbers, with a custom quantization factor. This was necessary because the optimizable function requires integer values for its hyper parameters (max iterations and sample size), and as such we have used the previously mentioned function with a quantization factor of 1.


\begin{lstlisting}[language=Python, caption=Example Search Space configuration, captionpos=b, label={lst:searchspace}]
config={
    "param1": 100,
    "param2": tune.uniform(10, 100),
    "param3": tune.quniform(0, 100,1),
    "param4": tune.choice(["choice1", "choice2", "choice2"]),

}
\end{lstlisting}

\paragraph{\acrshort{cam2} Interface}

To execute a \acrshort{pca} in \acrshort{cam2} we need to perform 2 actions: load the \acrshort{fcd} file and initiate the \acrshort{pca} functionality. This 2 step provided some challenges, seeing as there is no straight forward way to know which file is loaded into the CAM2 software. Overall we also found issues due to \acrshort{cam2} keeping files in memory, which creates some instability with larger files and further along the tuning session.

The file opening \acrshort{http} request returns an empty response, with only a status code, usually 202 (the standard response for an accepted HTTP request) or 40* (the usual code for a client error). The former happens when, for example, the file we are trying to open does not exist.

The \acrshort{pca} \acrshort{http} request returns a \acrshort{json} object, containing the maximum and mean values for the accuracy of the alignment, as you can see in the code excerpt \ref{lst:pcaresp}, as well  usually 202 when successful, or a empty response and a 40* status code. The former happens when, for example, the open file does not contain the selected point cloud.

\begin{lstlisting}[language=json, caption=Example \acrshort{pca} \acrshort{http} request response, captionpos=b, label={lst:pcaresp}]
{
    "max": 3.5536138345337953,
    "mean": 0.94855826840394786
}
\end{lstlisting}

To fix these issues, we implemented a actor, which we will further define in the following paragraph, and added fail safes, which allow the developer to restart the \acrshort{cam2}, if necessary, without stopping the training process. These fail safes can be seen in the code excerpt \ref{lst:cam2_pca} and \ref{lst:cam2_file}. Beside these measures, Ray Tune also automatically saves each trial run, and as such, in case of an error, we can restart or rerun a trial.

\begin{lstlisting}[language=Python, caption=Opening a \acrshort{fcd} file in \acrshort{cam2}, captionpos=b, label={lst:cam2_pca}]
def open_point_cloud_file(file_name):
    point_cloud_success=True
    # Grab the current file in CAM2, if available
    cam2_actor=ray.get_actor("CAM2Actor")
    try:
        cam2_file_name=ray.get(cam2_actor.get.remote())
    except TypeError:
        cam2_file_name=None
    # If file in CAM2 doesn't match the needed file, send a open file request
    if cam2_file_name != file_name or not point_cloud_success:
        full_path=path + file_name
        url=open_file_url + full_path
        while not file_success:
            file_success=False
            try:
                r_file=requests.post(url)
                file_success=r_file.ok
                ray.get(cam2_actor.set.remote(file_name))
            except Exception:
                print("Issues with CAM2 software connection, please restart the CAM2 software.")
                time.sleep(5)
        print("Loaded " + file_name + " into CAM2")
    else:
        print(file_name + " is already loaded into CAM2")
\end{lstlisting}

As you can see, we give appropriate time for a developer to restart \acrshort{cam2} when the file opening \acrshort{http} request fails. Besides this, we also use the actor functionality in Ray Tune (line 4-8), where we retrieve the current file loaded in CAM2, as logged by the Actor and the previously running trials and in line 18, when we have successfully loaded a new file into \acrshort{cam2} and update the Actor service accordingly.

\begin{lstlisting}[language=Python, caption=Running \acrshort{pca} function in \acrshort{cam2}, captionpos=b, label={lst:cam2_file}]
def run_point_cloud_alignment(file_name, point_cloud_name, max_iterations, sample_size):
    file_success=False
    r_pointcloud=None
    success=False

    while not success:
        # Open file, if needed
        open_point_cloud_file(file_name)

        # Run PCA
        point_cloud_success=False
        params={'pointcloudName': point_cloud_name,
                  'maxIterations': max_iterations,
                  'sampleSize': sample_size}
        while not point_cloud_success:
            try:
                r_pointcloud=requests.post(run_alignment_url, params=params)
                point_cloud_success=r_pointcloud.ok
                success=True
            except Exception:
                input("Issues with CAM2 software connection, please restart the CAM2 software.")

    response_string=r_pointcloud.content.decode("UTF-8")
    response_dict=ast.literal_eval(response_string)
    print("Executed PC alignment on " + point_cloud_name
          + " (max: " + str(response_dict['max'])
          + ", mean: " + str(response_dict['mean']) + ")")
    return response_dict
\end{lstlisting}

Once again, we allow the developer to restart \acrshort{cam2} when the \acrshort{pca} \acrshort{http} request fails.

\subparagraph{Ray Tune Actor}

To accurately keep track of what file is open in the \acrshort{cam2} software within each different trial, we used a Actor, a stateful worker/service within Ray Tune. This service allows us to keep track of what is open on \acrshort{cam2}, without creating issues due to concurrency (where 2 trial runs try to open different files at the same time) or issues with data sharing between processes (where a given trial is unable to share its state with other trials). 

The Actor is defined before the tuning session, as seen in the code excerpt \ref{lst:actor}. After defining an Actor, we are then able to create within the Ray Tune framework and get its current value and update its value from any running trial.

\begin{lstlisting}[language=Python, caption=Initiating a Ray Tune Actor, captionpos=b, label={lst:actor}]
# define CAM2 Actor
@ray.remote
class CAM2Tracker(object):
    def __init__(self):
        self.value=None

    def set(self, value):
        self.value=value
        return self.value

    def get(self):
        return self.value

# initiate the Ray Tune framework
ray.init()

# create the CAM2 open file tracker Actor
cam2=CAM2Tracker.options(name="CAM2Actor").remote()
\end{lstlisting}

\paragraph{Tuning Setup}

To setup a tuning session, it is required to define various configuration parameters ahead of time, such as the search spaces. We have separated the search space definition as a separate section, but the remaining configuration parameters are included in this section.

\begin{lstlisting}[language=Python, caption=Tuning session configuration example, captionpos=b, label={lst:setupex}]
tune.run(
    trainable,
    config={
        "max_iterations": tune.quniform(1,10000,1),
        "sample_size": tune.quniform(1,1000,1)},
    name="bohb_search",
    scheduler=HyperBandForBOHB(
        time_attr="training_iteration",
        max_t=100,
        reduction_factor=4),
    stop={"training_iteration": 100},
    search_alg=TuneBOHB(
        max_concurrent=1),
    metric="avg_percentage_diff",
    mode="max",
    num_samples=100,
    resources_per_trial={"cpu": 1},
    fail_fast=True,
    callbacks=[WandbLoggerCallback(
        project="Point Cloud Alignment Project",
        api_key="-----------------------",
        log_config=True)]
)
\end{lstlisting}

An example of a configuration for a tuning session can be seen in the code excerpt \ref{lst:setupex}.

\subparagraph{Trainable Object}

Although we created the required interfacing methods and tracking services, we still need to treat the obtained data and report it correctly to the Ray Tune framework. To do this, Ray Tune provides two \acrshort{api}: the Class \acrshort{api} and the function \acrshort{api}. 

The function \acrshort{api} allows a Python function to be used, requiring only a \verb!yield! or \verb!tune.report! command to report data and two input variables: a \verb!config! object containing the hyper parameter values to be used and a \verb!checkpoint_dir! variable, which is provided if we are resuming a paused trial.

Meanwhile, the Class \acrshort{api} requires to define a \verb!ray.tune.Trainable! subclass. This subclass requires implementing three methods: 

\begin{itemize}
    \item a \verb!setup! function, which is invoked when the training starts.
    \item a \verb!step! function, which is invoked multiple times and executes one logical process, which, in this project, is equivalent to one \acrshort{pca} execution.
    \item a \verb!cleanup! function, which is invoked when the training ends.
\end{itemize}

In this project we have used the function \acrshort{api}, specifically due to the ability to report multiple metrics using \verb!yield!. A abridged implementation is shown in the code excerpt \ref{lst:trainable}.

\begin{lstlisting}[language=Python, caption=Abridged Trainable function, captionpos=b, label={lst:trainable}]
def trainable(config, checkpoint_dir=None):
    # define variables

    # load configuration values
    max_iterations=config['max_iterations']
    sample_size=config['sample_size']


    while current_file < len(fcd_files_point_clouds):
        # load data from a checkpoint, if available 
        if checkpoint_dir:
            with open(os.path.join(checkpoint_dir, "checkpoint")) as f:
                state=json.loads(f.read())
                current_file=state["file"]
                last_point_cloud=state["pointcloud"]
                total_runs=state["total_runs"]
                avg_mean_percentage_diff=state["average_max_delta"]
                avg_max_percentage_diff=state["average_mean_delta"]

        #open file if needed

        while current_point_cloud < len(fcd_files_point_clouds[current_file][1]):
            # execute PCA algorithm

            # save data in a checkpoint
            with tune.checkpoint_dir(step=current_file) as checkpoint_dir:
                with open(os.path.join(checkpoint_dir, "checkpoint"), "w") as f:
                    f.write(json.dumps({"file": current_file,
                                        "pointcloud": current_point_cloud - 1,
                                        "average_max_delta": avg_mean_percentage_diff,
                                        "average_mean_delta": avg_max_percentage_diff,
                                        "total_runs": total_runs}))

            # forward data to Ray Tune
            yield {"avg_percentage_diff": opt_delta,
                   "percentage_diff": mean_percentage_diff,
                   "mean_delta": mean_delta,
                   "max_delta": max_delta,
                   "run_time": total_time}
\end{lstlisting}

\subparagraph{\acrshort{hpo} Algorithm}

Each tuning session requires defining which algorithm will be used to explore the search spaces. One of the reasons we have chosen to use the Ray Tune framework in this internship is its plethora of available algorithms to choose from. Specifically, and due to time/computational restrictions, we have used two algorithms: random search and \acrshort{bohb}. We have also defined configurations for a implementation of \acrshort{tpe} algorithm, through HyperOpt \parencite{10.5555/3042817.3042832}.

To select an algorithm, we create its search object, define its specific hyper parameters (e.g.\ constraints, initial values, reduction factors, time scale attributes and others), and pass the object to the Ray Tune session. We can see the definition of an algorithm configuration in the code excerpt \ref{lst:algconfig}.

\begin{lstlisting}[language=json, caption=Example algorithm configuration, captionpos=b, label={lst:algconfig}]
algorithm=AxSearch(
    max_concurrent=4,
    parameter_constraints=["x1 + x2 <= 2.0"],  # Optional.
    outcome_constraints=["l2norm <= 1.25"],  # Optional.
)
\end{lstlisting}

\subparagraph{Scheduler}

Some of the \acrshort{hpo} algorithm are written as ``scheduling algorithms'' within Ray Tune. To accomplish this, we use schedulers, which, in conjunction with the \acrshort{hpo} algorithm, can early terminate bad trials, pause trials, clone trials, and alter hyper parameters of a running trial. An example of a scheduler configuration can be seen in the code excerpt \ref{lst:schedconfig}.

\newpage
\begin{lstlisting}[language=Python, caption=Example trial scheduler configuration, captionpos=b, label={lst:schedconfig}]
asha_scheduler=ASHAScheduler(
    time_attr='training_iteration',
    metric='episode_reward_mean',
    mode='max',
    max_t=100,
    grace_period=10,
    reduction_factor=3,
    brackets=1)
)
\end{lstlisting}

Throughout this internship, we have used schedulers with the \acrshort{bohb} algorithm, as the \acrshort{hb} part requires the usage of the \verb!tune.schedulers.HyperBandScheduler! scheduler.

\subparagraph{Resources}

In order to limit resource usage as well as to force single-threading within the Ray Tune framework, we use resource allocation. With this, we can limit \acrshort{cpu} and \acrshort{gpu} thread usage. In order to enforce single-threading within each trial, we can limit each trial to use 1 \acrshort{cpu} thread, as well as limiting the Ray Tune framework available number of threads. To implement this feature we define a \verb!resources_per_trial! dictionary (as seen in the code excerpt \ref{lst:resconfig}) which is then passed on to the training session.

\begin{lstlisting}[language=Python, caption=Example resource allocation configuration, captionpos=b, label={lst:resconfig}]
resources_per_trial={
    "cpu": 64, 
    "gpu": 8
}
\end{lstlisting}

\subparagraph{Stop Criteria}

Additionally, we also have the ability to stop a trial based on a variety of factors, such as results, total iterations or time. To do this, we specify the \verb!stop! parameter within the tuning session setup. An example can be seen in the code excerpt \ref{lst:stopconfig}.

\begin{lstlisting}[language=Python, caption=Example stopping criteria configuration, captionpos=b, label={lst:stopconfig}]
stop={
    "training_iteration": 100
}
\end{lstlisting}

Within this project we define the stopping criteria as a total number of iterations (which is equivalent to the number of point cloud available).

\subparagraph{Metric Reporting}

A trial produces a large amount of data, from the results, parameters used and metadata (e.g.\ time of execution, start time). In order to being able to save this data outside a trial object, it is necessary to report it to the Ray Tune framework. To do this, we use the \verb!yield! function, which sends data to the Ray Tune framework from the trial object. Using this, we report a variety of data, besides the default metadata automatically collected by the Ray Tune framework. We specifically report the following data points:

\begin{itemize}
    \item average percentage difference over baseline, the percentage difference between the obtained results versus the baseline results, averaged for all already aligned point clouds
    \item percentage difference over baseline for the current point cloud
    \item delta over baseline for the average accuracy on the current point cloud
    \item delta over baseline for the maximum accuracy on the current point cloud
    \item run time for the \acrshort{cam2} \acrshort{pca} algorithm execution
\end{itemize}

We also need to define, from the reported data, which variable we are tracking and optimizing. This is necessary to evaluate the performance of a hyper parameter value set and to provide information for the \acrshort{hpo} algorithms. To do this, we need to define which of the reported metrics we are using for the optimization process as well as define how we are trying to optimizing said variable (maximizing or minimizing it). This is achieved by defining both of these in the tuning session setup, using the \verb!metric! and \verb!mode! parameters, as seen on \ref{lst:setupex}

\subparagraph{Logger}

As mentioned previously, we used the Weight and Biases service to show the obtained data visually. To do this, we need to send the obtained data to the WandB \acrshort{api}. This is done using the logger functionality within Ray Tune, where we can add a logger, in this case a \verb!WandbLoggerCallback! to the \verb!callbacks! parameter in the tuning session. We can see an example of this in the code excerpt \ref{lst:loggerconf}.

\begin{lstlisting}[language=Python, caption=Example WandB logger configuration, captionpos=b, label={lst:loggerconf}]
callbacks=[
    WandbLoggerCallback(
        project="Point Cloud Alignment Project",
        api_key="--------------",
        log_config=True
    )
]
\end{lstlisting}