%!TEX root = ../../main.tex

\section{State of the Art}

Every \acrshort{machinel} algorithm has hyper parameters \parencite[ch.\ 1]{Feurer2019} which control the learning process. These parameters also exist in other algorithms (e.g.\ population control parameters in evolutionary algorithms \parencite{ptuningevo2011}). These parameters are usually relevant to the final result of training an algorithm \parencite{Bergstra2012}. \todo{Change this to discuss other topics besides HPO (virtualization, APIs, other?).}

Hyper parameters can be set to default values (usually handled by the software packages used) or to community accepted values (usually based on experience and previous literature). This approach is usually discarded when the number of parameters is increased (as the community can't test and validate all hyper parameter values).

With the advancements of technology and machine learning research, new approaches to \acrshort{hpo} were developed that allow for searching the solution space (hyper parameter possible values) in an automated way.

\input{chapters/mainmatter/state-art/related-works}

\input{chapters/mainmatter/state-art/existing-tech}