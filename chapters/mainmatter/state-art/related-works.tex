%!TEX root = ../../../main.tex

\subsection{Related Works}

Automated \acrshort{hpo} approaches can be separated by their approaches with regards to the optimizable function (see Figure \ref{fig:state_of_art_taxonomy}). Here we split different algorithms into black-box and multi-fidelity based solutions.

Not all available algorithms were researched, focusing instead on different approaches, usage across the \acrshort{machinel} field and historic significance.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.75\textwidth]{images/state_art-taxonomy_optimizers.png}
	\caption{A Taxonomy for the Hyper-parameter Optimization Techniques \parencite{elshawi2019automated}.}
	\label{fig:state_of_art_taxonomy}
\end{figure}

\subsubsection{Black-Box Optimization Algorithms}

Black-box optimization algorithms treats the problem functions as black-boxes (any process that is not analytically available) \parencite[ch.~1]{book}. Therefore, any algorithm that does not directly infer any information from the problem function and uses zero or one models to produce results is considered to be a black box algorithm.

\subparagraph{Grid Search}
Traditionally grid search is used for \acrshort{hpo} \parencite{liashchynskyi2019grid} whereas a researcher or developer predefines possible values for a given hyper parameter and tests every hyper parameter combination from the solution space provided (see Figure \ref{grid}).

\begin{figure}[ht]
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			title={Solution space for 2 hyper parameters},
		    xlabel={Hyper parameter $\alpha$},
		    ylabel={Hyper parameter $\beta$},
		    xmin=0, xmax=6,
		    ymin=0, ymax=6,
		    xtick={0,1,2,3,4,5},
		    ytick={0,1,2,3,4,5},
		    ymajorgrids=true,
		    xmajorgrids=true,
		    xticklabels={},
		    yticklabels={}
		]
		\addplot+[
			only marks,
		    mark options={color=lightblue},
		    mark=*,
		    mark size=2.9pt]
		    coordinates {
		    (0.5,0.5)(0.5,1)(0.5,1.5)(0.5,2)(0.5,2.5)(0.5,3)(0.5,3.5)(0.5,4)(0.5,4.5)(0.5,5)(0.5,5.5)
		    (1,0.5)(1,1)(1,1.5)(1,2)(1,2.5)(1,3)(1,3.5)(1,4)(1,4.5)(1,5)(1,5.5)
		    (1.5,0.5)(1.5,1)(1.5,1.5)(1.5,2)(1.5,2.5)(1.5,3)(1.5,3.5)(1.5,4)(1.5,4.5)(1.5,5)(1.5,5.5)
		    (2,0.5)(2,1)(2,1.5)(2,2)(2,2.5)(2,3)(2,3.5)(2,4)(2,4.5)(2,5)(2,5.5)
		    (2.5,0.5)(2.5,1)(2.5,1.5)(2.5,2)(2.5,2.5)(2.5,3)(2.5,3.5)(2.5,4)(2.5,4.5)(2.5,5)(2.5,5.5)
		    (3,0.5)(3,1)(3,1.5)(3,2)(3,2.5)(3,3)(3,3.5)(3,4)(3,4.5)(3,5)(3,5.5)
		    (3.5,0.5)(3.5,1)(3.5,1.5)(3.5,2)(3.5,2.5)(3.5,3)(3.5,3.5)(3.5,4)(3.5,4.5)(3.5,5)(3.5,5.5)
		    (4,0.5)(4,1)(4,1.5)(4,2)(4,2.5)(4,3)(4,3.5)(4,4)(4,4.5)(4,5)(4,5.5)
		    (4.5,0.5)(4.5,1)(4.5,1.5)(4.5,2)(4.5,2.5)(4.5,3)(4.5,3.5)(4.5,4)(4.5,4.5)(4.5,5)(4.5,5.5)
		    (5,0.5)(5,1)(5,1.5)(5,2)(5,2.5)(5,3)(5,3.5)(5,4)(5,4.5)(5,5)(5,5.5)
		    (5.5,0.5)(5.5,1)(5.5,1.5)(5.5,2)(5.5,2.5)(5.5,3)(5.5,3.5)(5.5,4)(5.5,4.5)(5.5,5)(5.5,5.5)
		    };
		\end{axis}
	\end{tikzpicture}
    \caption{Illustration of a grid search. The possible parameters are manually set and the algorithm does an exhaustive search on all the possible combinations.}
    \label{grid}
 \end{figure}

\subparagraph{Random Search} This method is similar to grid search, but replaces manually set values with ranges and allows for randomized selection of hyper parameter values (see Figure \ref{random}). This method has been proven to be more efficient than grid search \parencite{JMLR:v13:bergstra12a}.

\begin{figure}[ht]
	\centering
	\begin{tikzpicture}
		\begin{axis}[
			title={Solution space for 2 hyper parameters},
		    xlabel={Hyper parameter $\alpha$},
		    ylabel={Hyper parameter $\beta$},
		    xmin=0, xmax=6,
		    ymin=0, ymax=6,
		    xtick={0,1,2,3,4,5},
		    ytick={0,1,2,3,4,5},
		    ymajorgrids=true,
		    xmajorgrids=true,
		    xticklabels={},
		    yticklabels={}
		]
		\addplot+[
			only marks,
		    mark options={color=lightblue},
		    mark=*,
		    mark size=2.9pt]
		    coordinates {
				(1.5,4)(2.5,4.1)(1.4,3)(1.6,3.6)(5.3,2.5)(5.4,2.3)(2.7,3.6)(1.5,5.1)(3.5,1.1)(3.1,5.7)(3.3,3.1)(3.5,1.8)(4.7,5.4)(3.7,2)(4.7,2.2)(2.7,2.4)(3.6,5.6)(2.5,5.9)(1.7,2.7)(4.1,5.9)
		    };
		\end{axis}
	\end{tikzpicture}
    \caption{Illustration of a random search. The hyper parameters values are randomly generated and the algorithm searches all the combinations.}
    \label{random}
 \end{figure}

\subparagraph{Simulated Annealing}

This algorithm is based in the annealing process observed in metallurgy, where metal is heated to a high temperature and then slowly cooled, allowing for atoms in the metal to settle into more stable configurations \parencite{elshawi2019automated}.

Analogously, simulated annealing maintains a single candidate solution and takes steps of random size from the candidate in the search space, replacing the current candidate with a better solution or, with a certain probability, a worse one.

\subparagraph{Bayesian Optimization}

Bayesian optimization can be described as sequential model-based optimization, whereas a probabilistic model is updated after every optimization attempt \parencite{dewancker}.

Various probabilistic regression models can be used (e.g. Gaussian Processes and Random Forests). One of these regression models, Tree Parzen Estimators, deviates from the standard regression models, which use a predictive distribution $p(y|x)$. Instead, it creates two density functions that act as generative models for all domain variables \parencite{NIPS2011_86e8f7ab}\parencite{elshawi2019automated}.

\subparagraph{Population-based Optimization}

This optimization technique is a hybrid of two methods of \acrshort{hpo}: random search and hand-tuning.

It starts by training a number of individual algorithms with random hyper parameters. But, instead of each algorithm working individually, they share information between them, to refine parameters and manage computational resources to solution sets that show promising results \parencite{jaderberg2017population}.

\subparagraph{Genetic Algorithms}

This set of optimization methods use algorithms inspired by biological evolution.

These algorithms are usually based on the idea of applying the multiple genetic operations (crossover, mutation, survival of the fittest) to a population of configurations \parencite{elshawi2019automated}.

\subparagraph{Gradient-based Optimization}

This algorithm uses the gradient of the model selection criterion with respect to the hyper parameters \parencite{bengio2000}. This algorithm is unsuitable when the optimizable function is treated as a black box function (where we only have access to  its output and inputs).

\subparagraph{Spectral Optimization}

This algorithm is inspired by techniques used in analysis of Boolean functions \parencite{hazan2017hyperparameter}. It specifically uses an iterative application of compressed sensing technique, allowing for easier parallelization.

\subsubsection{Multi-Fidelity Optimization Algorithms}

An area of increased attention in the \acrshort{hpo} research field is multi-fidelity techniques. These methods focus on decreasing the evaluation cost of a given function by combining cheap low-fidelity and expensive high-fidelity evaluations \parencite{elshawi2019automated}. These techniques are essential for optimization in high cost functions, where optimizing one hyper parameter can take days.

\paragraph{Bandit-based Optimization}

These techniques are based on the \textit{multi-armed bandit problem}, whereas a limited set of resources must be allocated between competing choices, maximizing expected gain \parencite{Katehakis1987TheMB}. Similarly, using this class of algorithms in \acrshort{hpo} allows computers to stop the execution of a trial (with defined hyper parameter values), by analysing observable features during the run. This also leads to a decrease in computational power and time required to tune hyper parameters. 

\subparagraph{Successive Halving} 
This algorithm is an example of a bandit-based approach to the \acrshort{hpo} problem \parencite{jamieson2015nonstochastic}. Here the optimization process begins as a random search with periodical pruning of lower performing trials, therefore saving time and computational resources. 

\subparagraph{HyperBand}
This algorithm is based on bandit-based optimization, solving the issue of time allocation \textit{in lieu} of search time. As an example, \textit{successive halving} incurs on an issue regarding whether to allocate a large part of the time budget on exploring a large number of solutions rather than tuning a small number of them \parencite{elshawi2019automated}. \textit{HyperBand} attempts to solve this issue by partitioning the original time budget into smaller time and budget combinations and using \textit{successive halving} on each configuration \parencite{li2016hyperband}.

\subparagraph{BOHB (Bayesian Optimization and HyperBand)}
This algorithm is a combination of bayesian optimization and HyperBand, bringing together the best of both black-box and multi-fidelity optimization algorithms \parencite{pmlr-v80-falkner18a}. This algorithm works using a initial stage of successive halving (HyperBand), which optimizes a given function quickly, using early termination and parallel computation, while at the same time building a probability model using the results from said stage, which it uses in a second stage, significantly improving the speed at which the hyper parameters converge to optimal configurations.

\paragraph{Learning Curve Modelling}
Within more specific tasks (such as \acrfull{dnn}), \acrshort{hpo} can be performed by modelling the learning curve of a given function or network and using this model to extrapolate optimal hyper parameter values \parencite{10.5555/2832581.2832731}. As this type of optimization is outside the scope of this project (seeing as it is meant to handle general functions), we do not investigate this optimization algorithm typology further.